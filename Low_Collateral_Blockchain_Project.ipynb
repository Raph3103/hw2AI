{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Raph3103/hw2AI/blob/main/Low_Collateral_Blockchain_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nv0qzgkl8fa"
      },
      "source": [
        "# Low Collateral Blockchain Project\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 564,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZXKVH5nl8fd",
        "scrolled": false,
        "outputId": "0d92954f-3676-4229-ce04-96612e64efa3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 565,
      "metadata": {
        "id": "DsJ-C0L3l8fe",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULM8nHMul8ff"
      },
      "source": [
        "Get the stat file: We will start by obtaining the stat file, which contains relevant data for our analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 566,
      "metadata": {
        "id": "YCq-Dwiel8ff"
      },
      "outputs": [],
      "source": [
        "data = pd.read_pickle('/content/HistoryPoolBorrowersStats.pkl')\n",
        "\n",
        "df = pd.DataFrame.from_dict(data,orient='index')\n",
        "\n",
        "chemin_fichier_csv = 'newStats.csv'\n",
        "\n",
        "df.to_csv(chemin_fichier_csv, index=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5CnrkV_l8fg"
      },
      "source": [
        "Add columns and modify the existing file: We will enhance the stat file by adding new columns and modifying existing ones to better suit our analysis requirements.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 567,
      "metadata": {
        "id": "lAwVZbZXl8fg"
      },
      "outputs": [],
      "source": [
        "# Read the CSV file into a dataframe\n",
        "df = pd.read_csv('newStats.csv')\n",
        "\n",
        "# Remove columns\n",
        "columns_to_remove = ['datesSupplyCollateral', 'datesLoan','datesReimbursement','datesWithdrawCollateral','timeUTCFirstAnyTransactionAccount','borrowerAgeInYears','totalLoans','NumLoans','MeanLoans','totalTimeloans','MeanTimeLoans','totalSupplyCollateral','NumSupplyCollateral','MeanSupplyCollateral','totalReimbursements','NumReimbursements','MeanReimbursements','NumTransactions']  # Specify the names of the columns to remove\n",
        "df = df.drop(columns=columns_to_remove)\n",
        "\n",
        "\n",
        "# Save the modified dataframe to a new CSV file\n",
        "df.to_csv('newStats.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C21x-gy0xWs5"
      },
      "source": [
        "This part transfor the dict from date keys to tomestamps keys and also add a new value named ratio for each timestamsp if size debt = 0 then collateralDebtRatio = infinity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 568,
      "metadata": {
        "id": "AGSg8wuuGV--"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "from datetime import datetime\n",
        "import time\n",
        "\n",
        "# Load the csv file\n",
        "df = pd.read_csv('newStats.csv')\n",
        "\n",
        "\n",
        "# Define a helper function to convert a date to a timestamp\n",
        "def date_to_timestamp(date_str):\n",
        "    dt_object = datetime.strptime(date_str, \"%Y-%m-%d\")\n",
        "    timestamp = int(time.mktime(dt_object.timetuple()))\n",
        "    return timestamp\n",
        "\n",
        "# Iterate over the Calendar column\n",
        "for i, cell in enumerate(df['Calendar']):\n",
        "    if isinstance(cell, str):\n",
        "        # Replace single quotes with double quotes\n",
        "        cell = cell.replace(\"'\", '\"')\n",
        "        # Load the dictionary\n",
        "        calendar_dict = json.loads(cell)\n",
        "        new_calendar_dict = {}\n",
        "\n",
        "        # Iterate over the days in the calendar_dict\n",
        "        for date_str, day_dict in calendar_dict.items():\n",
        "            # Convert the date to a timestamp and replace it in the dictionary\n",
        "            timestamp = date_to_timestamp(date_str)\n",
        "\n",
        "            # Compute the ratio and insert it into the dictionary\n",
        "            if day_dict['sizeDebtUSD'] != 0:\n",
        "                ratio = day_dict['sizeCollateralUSD'] / day_dict['sizeDebtUSD']\n",
        "            else:\n",
        "                ratio = float('inf')\n",
        "            day_dict['collateralDebtRatio'] = ratio\n",
        "\n",
        "            new_calendar_dict[timestamp] = day_dict\n",
        "\n",
        "        # Replace the row's value in the DataFrame with the updated dictionary\n",
        "        df.at[i, 'Calendar'] = json.dumps(new_calendar_dict)\n",
        "    else:\n",
        "        continue\n",
        "\n",
        "# Save the updated DataFrame back to csv\n",
        "df.to_csv('newStats.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUeNPet2ysVm"
      },
      "source": [
        "adding most frequent time in the day"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 569,
      "metadata": {
        "id": "8sDYb_wSODZd"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# Define function to convert UNIX timestamp to time of day category\n",
        "def timestamp_to_category(timestamp):\n",
        "    # Convert timestamp to datetime\n",
        "    dt_object = datetime.fromtimestamp(int(float(timestamp)))  # Modify this line\n",
        "    hour = dt_object.hour\n",
        "\n",
        "    # Assign time of day category based on hour\n",
        "    if 6 <= hour < 12:\n",
        "        return \"Morning\"\n",
        "    elif 12 <= hour < 18:\n",
        "        return \"Afternoon\"\n",
        "    elif 18 <= hour < 24:\n",
        "        return \"Evening\"\n",
        "    else:\n",
        "        return \"Night\"\n",
        "\n",
        "# Define function to find the most frequent category in a list\n",
        "def most_frequent_category(lst):\n",
        "    return max(set(lst), key=lst.count) if lst else None\n",
        "\n",
        "# Load the csv file\n",
        "df = pd.read_csv('newStats.csv')\n",
        "\n",
        "# Define the timestamp columns to examine\n",
        "timestamp_cols = ['timeStampsSupplyCollateral', 'timeStampsLoans', 'timeStampsReimbursement', 'timeStampsWithdrawCollateral', 'timeStampFirstAnyTransactionAccount']\n",
        "\n",
        "# Create a new column for the time of day of most transactions\n",
        "df['MostFrequentTransactionTimeOfDay'] = \"\"\n",
        "\n",
        "# Iterate over the DataFrame rows\n",
        "for i, row in df.iterrows():\n",
        "    categories = []\n",
        "    # For each timestamp column, convert the timestamps to categories and add them to the list\n",
        "    for col in timestamp_cols:\n",
        "        if pd.isnull(row[col]):\n",
        "            continue\n",
        "        timestamps = str(row[col]).split()\n",
        "        for timestamp in timestamps:\n",
        "            categories.append(timestamp_to_category(timestamp))\n",
        "    # Determine the most frequent category and assign it to the new column\n",
        "    df.at[i, 'MostFrequentTransactionTimeOfDay'] = most_frequent_category(categories)\n",
        "\n",
        "# Save the updated DataFrame back to csv\n",
        "df.to_csv('newStats.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G98wEsVFy9Fp"
      },
      "source": [
        "count the number of days with high ratio(1 but we can change the value if needed) for each user, using the new value in the calendar colomn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 570,
      "metadata": {
        "id": "5HOszi7OX36u"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "threshold = 2.2\n",
        "\n",
        "def count_days_with_high_ratio(calendar_str):\n",
        "    # Check if calendar_str is a string\n",
        "    if not isinstance(calendar_str, str):\n",
        "        # Return None (or 0, depending on your needs) if not\n",
        "        return None  # or return 0\n",
        "\n",
        "    # Convert string to dictionary\n",
        "    calendar = json.loads(calendar_str)\n",
        "\n",
        "    count = 0\n",
        "    for day, attributes in calendar.items():\n",
        "        if 'collateralDebtRatio' in attributes and attributes['collateralDebtRatio'] > threshold:\n",
        "            count += 1\n",
        "    return count\n",
        "\n",
        "# Create a new column for the count of days with collateralDebtRatio > 13\n",
        "df['DaysWithHighRatio'] = df['Calendar'].apply(count_days_with_high_ratio)\n",
        "# Save the updated DataFrame back to csv\n",
        "df.to_csv('newStats.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35-yeA_AA4Pv"
      },
      "source": [
        "if the user paid x percent in the last y month the val is true"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 571,
      "metadata": {
        "id": "6izVyBdscZzp"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import time\n",
        "\n",
        "x_percent=0.1\n",
        "\n",
        "y_month=9\n",
        "def loan_repaid_x_percent_in_last_y_months(calendar):\n",
        "    # Define the timestamp for 9 months before the day you stopped computing the file\n",
        "    six_months_ago = 1668297600 - y_month*30*24*60*60\n",
        "\n",
        "    # Load the dictionary from the calendar cell\n",
        "    if isinstance(calendar, str):\n",
        "        calendar_dict = json.loads(calendar)\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "    # Initialize the total loan and total repayment amounts\n",
        "    total_loan = 0\n",
        "    total_repayment = 0\n",
        "\n",
        "    # Iterate over the days in the calendar_dict\n",
        "    for timestamp, day_dict in calendar_dict.items():\n",
        "        # Convert the timestamp to an integer\n",
        "        timestamp = int(timestamp)\n",
        "\n",
        "        # If the timestamp is within the last 6 months and not before the user's first day\n",
        "        if six_months_ago <= timestamp <= 1668297600:\n",
        "            # Add the loan and repayment amounts for the day to the totals\n",
        "            total_loan += day_dict['sizeDebtUSD']\n",
        "            total_repayment += day_dict['amountPaymentsOnDay']\n",
        "\n",
        "    # If the total loan amount is 0, return False\n",
        "    if total_loan == 0:\n",
        "        return False\n",
        "\n",
        "    # Calculate the repayment percentage\n",
        "    repayment_percentage = total_repayment / total_loan\n",
        "\n",
        "    # If the repayment percentage is at least 66%, return True\n",
        "    if repayment_percentage >= x_percent:\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "# Apply the function to the Calendar column to create a new column\n",
        "df['LoanRepaidxPercentInLastyMonths'] = df['Calendar'].apply(loan_repaid_x_percent_in_last_y_months)\n",
        "\n",
        "\n",
        "# Save the updated DataFrame back to csv\n",
        "df.to_csv('newStats.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDxL3wRIl8fg"
      },
      "source": [
        "Create a function to evaluate user behavior: We will develop a function that determines whether a user is classified as good or bad based on their activities on our platform. This function will help us assess user behavior and identify potential risks.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 572,
      "metadata": {
        "id": "ipRb7__Hl8fg"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Get today's date\n",
        "today = datetime.now()\n",
        "\n",
        "six_months_ago = today - timedelta(days=15*30)  # Assuming each month has 30 days\n",
        "\n",
        "# Convert the dates to timestamps\n",
        "timestamp_today = int(today.timestamp())\n",
        "timestamp_six_months_ago = int(six_months_ago.timestamp())\n",
        "\n",
        "\n",
        "def evaluate_user_behavior(row):\n",
        "    conditions_met = 0\n",
        "\n",
        "\n",
        "    if row['DaysWithHighRatio'] > 60:\n",
        "        conditions_met += 2\n",
        "        if row['LoanRepaidxPercentInLastyMonths']:\n",
        "          conditions_met += 4\n",
        "    if row['timeStampFirstAnyTransactionAccount'] < timestamp_six_months_ago :\n",
        "        conditions_met += 1\n",
        "\n",
        "    if conditions_met==5 or conditions_met == 6 or conditions_met==7 or conditions_met == 3:\n",
        "        return 'Good'\n",
        "    elif conditions_met ==0 :\n",
        "        return 'Bad'\n",
        "    else:\n",
        "        return 'Unknown'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDRE0T7Sl8fh"
      },
      "source": [
        "Run the function for all rows: We will iterate over each row of the stat file and apply the user evaluation function to determine the classification for each user.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 573,
      "metadata": {
        "id": "LYNHcE2Kl8fh"
      },
      "outputs": [],
      "source": [
        "df['user_class'] = df.apply(evaluate_user_behavior, axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "290gzDGil8fh"
      },
      "source": [
        "Add the new column to the CSV: After evaluating all the users, we will add the newly generated classification column to the CSV file.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 574,
      "metadata": {
        "id": "fM234biwl8fi"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = df.drop(columns='Calendar')\n",
        "\n",
        "# Save the DataFrame as a CSV file\n",
        "df.to_csv('updated_data.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nF7eGzRVl8fi"
      },
      "source": [
        "Run a machine learning model: With the updated CSV file, we will utilize a machine learning model to gain insights and predictions based on the user behavior data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 575,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBC7ipi8l8fi",
        "outputId": "b221bec3-9901-47e2-fa1e-b915d0951b3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       sizeLoansUSD  sizeCollateralUSD  sizeReimbursementsUSD  numLoansUser  \\\n",
            "count  1.900000e+02       1.900000e+02           1.900000e+02    190.000000   \n",
            "mean   8.134692e+05       1.542747e+06           6.428475e+05      5.000000   \n",
            "std    3.418124e+06       6.631302e+06           3.151741e+06     13.317054   \n",
            "min    1.000000e+02       1.101659e+02           4.612872e+00      1.000000   \n",
            "25%    7.625024e+02       1.296070e+03           4.954414e+02      1.000000   \n",
            "50%    1.442505e+04       2.721747e+04           9.930242e+03      2.000000   \n",
            "75%    1.257161e+05       2.439932e+05           1.005268e+05      4.000000   \n",
            "max    3.913494e+07       6.396438e+07           3.914135e+07    156.000000   \n",
            "\n",
            "       numReimbursementsUser  ratioCollateralToLoans  \\\n",
            "count             190.000000              190.000000   \n",
            "mean                3.200000                2.049878   \n",
            "std                 7.024673                1.284903   \n",
            "min                 1.000000                0.135575   \n",
            "25%                 1.000000                1.394455   \n",
            "50%                 1.000000                1.759359   \n",
            "75%                 3.000000                2.375139   \n",
            "max                78.000000               12.960700   \n",
            "\n",
            "       averageOfDailyCollateralToDebt  numTransactionsUser  \\\n",
            "count                      190.000000           190.000000   \n",
            "mean                         2.255415            15.657895   \n",
            "std                          1.632461            27.716131   \n",
            "min                          1.000000             3.000000   \n",
            "25%                          1.501333             5.000000   \n",
            "50%                          1.959840             8.000000   \n",
            "75%                          2.643076            15.000000   \n",
            "max                         18.107294           259.000000   \n",
            "\n",
            "       timeStampFirstAnyTransactionAccount  MostFrequentTransactionTimeOfDay  \\\n",
            "count                         1.900000e+02                        191.000000   \n",
            "mean                          1.620535e+09                          1.570681   \n",
            "std                           4.724120e+07                          1.121080   \n",
            "min                           1.492597e+09                          0.000000   \n",
            "25%                           1.600501e+09                          1.000000   \n",
            "50%                           1.636517e+09                          2.000000   \n",
            "75%                           1.658208e+09                          3.000000   \n",
            "max                           1.670193e+09                          4.000000   \n",
            "\n",
            "       DaysWithHighRatio  LoanRepaidxPercentInLastyMonths  user_class  \n",
            "count         190.000000                       191.000000  191.000000  \n",
            "mean           19.305263                         0.198953    1.764398  \n",
            "std            25.754261                         0.400262    0.554398  \n",
            "min             0.000000                         0.000000    0.000000  \n",
            "25%             1.000000                         0.000000    2.000000  \n",
            "50%             6.000000                         0.000000    2.000000  \n",
            "75%            27.250000                         0.000000    2.000000  \n",
            "max           101.000000                         1.000000    2.000000  \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         9\n",
            "           1       0.11      0.06      0.07        18\n",
            "           2       0.82      0.91      0.86       126\n",
            "\n",
            "    accuracy                           0.76       153\n",
            "   macro avg       0.31      0.32      0.31       153\n",
            "weighted avg       0.68      0.76      0.72       153\n",
            "\n",
            "152    1\n",
            "75     2\n",
            "158    2\n",
            "66     2\n",
            "60     2\n",
            "      ..\n",
            "163    1\n",
            "131    2\n",
            "17     2\n",
            "72     2\n",
            "167    2\n",
            "Name: user_class, Length: 153, dtype: int64\n",
            "-------------------------------------\n",
            "[2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 0 2 2 2 2 2 2 2 2 1 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1\n",
            " 2 1 2 2 2]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "# Read the data\n",
        "df = pd.read_csv('updated_data.csv')\n",
        "#print(df.describe())\n",
        "# Drop unnecessary column\n",
        "df = df.drop(columns=['Unnamed: 0'])\n",
        "#df = df.drop(columns=['Calendar'])\n",
        "# Handle timestamp strings\n",
        "# Handle timestamp strings\n",
        "for col in ['timeStampsSupplyCollateral', 'timeStampsLoans', 'timeStampsReimbursement', 'timeStampsWithdrawCollateral','maximumDebt', 'atTimeMaximumDebtCollateralProvided']:\n",
        "    df= df.drop(columns=col)\n",
        "\n",
        "rows_with_nan = df[df.isna().any(axis=1)]\n",
        "\n",
        "df.dropna()\n",
        "# Convert boolean to int\n",
        "df['LoanRepaidxPercentInLastyMonths'] = df['LoanRepaidxPercentInLastyMonths'].astype(int)\n",
        "\n",
        "# Handle categorical columns\n",
        "le = preprocessing.LabelEncoder()\n",
        "df['MostFrequentTransactionTimeOfDay'] = le.fit_transform(df['MostFrequentTransactionTimeOfDay'])\n",
        "df['user_class'] = le.fit_transform(df['user_class'])\n",
        "\n",
        "# Extract features from Calendar dictionary (you need to specify this according to the dictionary's structure)\n",
        "print(df.describe())\n",
        "# Normalize numerical columns\n",
        "scaler = StandardScaler()\n",
        "num_cols = ['sizeLoansUSD', 'sizeCollateralUSD', 'sizeReimbursementsUSD', 'numLoansUser', 'ratioCollateralToLoans', 'averageOfDailyCollateralToDebt', 'numTransactionsUser', 'DaysWithHighRatio']\n",
        "df[num_cols] = scaler.fit_transform(df[num_cols])\n",
        "\n",
        "# Define features and target\n",
        "for cols in ['DaysWithHighRatio','timeStampFirstAnyTransactionAccount','LoanRepaidxPercentInLastyMonths']:\n",
        "  df = df.drop(columns=cols)\n",
        "X = df.drop('user_class', axis=1)\n",
        "y = df['user_class']\n",
        "\n",
        "#print(X.head())\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.80, random_state=42)\n",
        "\n",
        "\n",
        "# Drop rows with NaN values\n",
        "X_train = X_train.dropna()\n",
        "y_train = y_train[X_train.index]\n",
        "\n",
        "# Create a model\n",
        "rfc = RandomForestClassifier( n_estimators=100, random_state=42)\n",
        "\n",
        "# Fit the model\n",
        "rfc.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = rfc.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(y_test)\n",
        "print('-------------------------------------')\n",
        "print(y_pred)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TRX8y-Bl8fi"
      },
      "source": [
        "Analyze performance: Finally, we will analyze the performance of our machine learning model and evaluate its effectiveness in predicting user behavior accurately."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 576,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 661
        },
        "id": "T5UQlICYl8fj",
        "outputId": "7cafd9e8-2963-4941-e0cd-e7c7459199c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            " [[  0   0   9]\n",
            " [  0   1  17]\n",
            " [  3   8 115]]\n",
            "Accuracy: 0.7581699346405228\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         9\n",
            "           1       0.11      0.06      0.07        18\n",
            "           2       0.82      0.91      0.86       126\n",
            "\n",
            "    accuracy                           0.76       153\n",
            "   macro avg       0.31      0.32      0.31       153\n",
            "weighted avg       0.68      0.76      0.72       153\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-576-f2cd5f4b86b9>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Calculate Area Under the Receiver Operating Characteristic Curve (ROC AUC)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mroc_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Area Under ROC Curve: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroc_auc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    563\u001b[0m             )\n\u001b[1;32m    564\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmulti_class\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"raise\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"multi_class must be in ('ovo', 'ovr')\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m         return _multiclass_roc_auc_score(\n\u001b[1;32m    567\u001b[0m             \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: multi_class must be in ('ovo', 'ovr')"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_auc_score\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = rfc.predict(X_test)\n",
        "\n",
        "# Print the Confusion Matrix and slice it into four pieces for future use\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print('Confusion Matrix:\\n', cm)\n",
        "\n",
        "# Calculate Accuracy, Precision, Recall, and F1-Score\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy}\\n')\n",
        "print(f'Classification Report:\\n{report}')\n",
        "\n",
        "# Calculate Area Under the Receiver Operating Characteristic Curve (ROC AUC)\n",
        "roc_auc = roc_auc_score(y_test, rfc.predict_proba(X_test)[:, 1])\n",
        "print('Area Under ROC Curve: ', roc_auc)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}